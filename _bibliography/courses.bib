---
---
@course{dae,
    title = {Deep {A}utoencoders and {V}ariational {A}utoencoders},
    content = {
    <ul>
      <li>Autoencoders: Motivation & History</li>
      <li>Autoencoders: Loss function</li>
      <li>Undercomplete Autoencoders</li>
      <li>Overcomplete Autoencoders</li>
      <li>Stacked / Deep Autoencoders</li>
      <li>Variational Autoencoders</li>
      <li>Applications of Autoencoders</li>
    </ul>
    },
    practical = {
    <b>Task</b>: Explore the use of autoencoders for
    <ul>
      <li>Data compression</li>
      <li>Data generation</li>
      <li>Data interpolation</li>
    </ul>
    <b>Dataset</b>: <a href="http://yann.lecun.com/exdb/mnist/" target="_blank"> MNIST</a><br>
    <b>Libraries</b>: PyTorch, torchvision <br><br>
    <b>Learning objectives</b>:
    <ul>
      <li>Build and train the following types of autoencoders</li>
      <ul>
        <li>Sparse autoencoder with L1 penalty</li>
        <li>Sparse autoencoder with KL penalty</li>
        <li>Contractive Autoenoder</li>
        <li>Variational Autoenoder</li>
      </ul>
      <li>Explore the quality of their learned latent space</li>
    </ul>
    },

    image={../images/resources/ae.png}

}

@course{nr,
    title = {Noise {R}eduction in {M}achine {L}earning},
    content = {
    <ul>
      <li>Sources of noise</li>
      <li>Impact of noise</li>
      <li>Examples of noise</li>
      <li>Noise reduction techniques</li>
      <ul>
        <li>Rolling Window</li>
        <li>Convolution</li>
        <li>Digital Filters</li>
        <li>Machine Learning Fitlers</li>
        <li>Denoising Autoencoders</li>
      </ul>
    </ul>
    },
    practical = {
    <b>Task</b>: Denoise corrupted images<br>
    <b>Dataset</b>: <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">Fashion MNIST</a><br>
    <b>Libraries</b>: PyTorch, torchvision <br><br>
    <b>Learning objectives</b>:
    <ul>
      <li>Build a simple Denoising Autoencoder (DAE) for images</li>
      <li>Train such a DAE on images with a given corrupted noise </li>
      <li>Visualize the quality of reconstruction</li>
    </ul>
    },
    image={../images/resources/watermarks.png}

}

@course{mna,
    title = {Advanced {C}onvolutional {N}eural {N}etwork {A}rchitectures (2012 - 2018)},
    content = {
    <ul>
      <li>History of vision architectures (1998-2012)</li>
      <li>Network in Network (2014)</li>
      <li>InceptionNet (2014)</li>
      <li>ResNet (2015)</li>
      <li>Pre-activations: Improved ResNet (2016)</li>
      <li>DenseNet (2016)</li>
      <li>WaveNet (2016)</li>
      <li>Depthwise Separable Convolutions (2017)</li>
      <li>Squeeze-and-Excite: ResNet (2017)</li>
      <li>Neural Architecture Search (2018 - Present)</li>
    </ul>
    },
    practical = {
    <b>Task</b>: Build an image classifier<br>
    <b>Dataset</b>: <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank"> CIFAR-10</a><br>
    <b>Libraries</b>: PyTorch, torchvision <br><br>
    <b>Learning objectives</b>:
    <ul>
      <li>Build and train <a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank">InceptionNet</a> on CIFAR-10</li>
      <li>Build and train <a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank">DenseNet</a> on CIFAR-10</li>
    </ul>

    },

    image={../images/resources/imagenet.png}

}
